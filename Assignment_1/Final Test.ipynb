{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import collections\n",
    "from tika import parser\n",
    "import re\n",
    "import xlwt\n",
    "from xlwt import Workbook\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "all_contents = []\n",
    "#link_url =[]\n",
    "contents = []\n",
    "#url_desc_list = []\n",
    "#url_pair_list = []\n",
    "with open(r'/Users/rajsharavan/Desktop/Python/url_state_street.csv','r') as csvf: # Open file in read mode\n",
    "    urls = csv.reader(csvf)\n",
    "    for url in urls:\n",
    "        contents.append(url[0])\n",
    "        \n",
    "row=1\n",
    "wb = Workbook()\n",
    "add = wb.add_sheet('count_sheet_6', cell_overwrite_ok=True)\n",
    "    \n",
    "col=5\n",
    "j=0\n",
    "add.write(0,0, 'Job ID')\n",
    "add.write(0,1, 'Instituion')\n",
    "add.write(0,2, 'List ID')\n",
    "add.write(0,3, 'URL')\n",
    "add.write(0,4, 'List ID')\n",
    "\n",
    "\n",
    "for joburl in contents[0:500]:\n",
    "    #print(joburl)\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(joburl)\n",
    "    # Selenium script to scroll to the bottom, wait 3 seconds for the next batch of data to load, then continue scrolling.  It will continue to do this until the page stops loading new data.\n",
    "    lenOfPage = browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "    match=False\n",
    "    while(match==False):\n",
    "        lastCount = lenOfPage\n",
    "        time.sleep(3)\n",
    "        lenOfPage = browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "        if lastCount==lenOfPage:\n",
    "    #        print('lastCount and lenOfPage matched: ',lenOfPage)\n",
    "            match=True\n",
    "\n",
    "    # Now that the page is fully scrolled, grab the source code.\n",
    "    source_data = browser.page_source\n",
    "    \n",
    "    # Throw your source into BeautifulSoup and start parsing!\n",
    "    bs_data = bs(source_data, \"lxml\")\n",
    "\n",
    "    job_descrp = bs_data.find_all('div',attrs={'class':'GWTCKEditor-Disabled'}) #extracts all the text in this tag\n",
    "\n",
    "    jobDescList = []\n",
    "\n",
    "    for job in job_descrp:\n",
    "        jobDescList.append(job.get_text())\n",
    "\n",
    "    # print(len(jobDescList))\n",
    "    # print(jobDescList[1])\n",
    "    browser.close()\n",
    "\n",
    "    string = \"\"\n",
    "\n",
    "    for i in range(0,(len(jobDescList)-1)):\n",
    "        string = string+jobDescList[i]\n",
    "\n",
    "    all_contents.append(string)\n",
    "    \n",
    "\n",
    "\n",
    "    def get_count(word_count_tuple):\n",
    "        return word_count_tuple[1]\n",
    "\n",
    "    word_counts = collections.Counter(all_contents)\n",
    "\n",
    "    # This function sorts the words based on the number of times repeated and saves them in a csv file\n",
    "    def print_top():\n",
    "        word_count = word_counts\n",
    "        items = sorted(word_count.items(),key=get_count,reverse=True)\n",
    "        with open(r'/Users/rajsharavan/Desktop/Python/Test/jobdesc_SS.csv','w') as out:\n",
    "            csv_out=csv.writer(out)\n",
    "            csv_out.writerow('')\n",
    "            #csv_out.writerow('Name')\n",
    "            for row in items:\n",
    "                csv_out.writerow(row)\n",
    "    print_top()\n",
    "\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "    i=0\n",
    "    for data in all_contents:\n",
    "        word_tokens1 = word_tokenize(data)\n",
    "        words1 = [w for w in word_tokens1 if w.isalpha()]\n",
    "        #print(type(words1))\n",
    "        filtered_sentence = []\n",
    "        i = i+1\n",
    "#        print(\"DATA\", i)\n",
    "        for w in words1: \n",
    "            w.lower()\n",
    "            #print(w.lower())\n",
    "            if w.lower() not in stop_words: \n",
    "                filtered_sentence.append(w)\n",
    "                #print('Total Words :',len(filtered_sentence))\n",
    "        #print(filtered_sentence)\n",
    "    \n",
    "        word_counts = collections.Counter(filtered_sentence)\n",
    "\n",
    "    # It sorts the words xbased on the number of times repeated and saves them in a csv file\n",
    "    def print_top1():\n",
    "        word_count = word_counts\n",
    "        items = sorted(word_count.items(),key=get_count,reverse=True)\n",
    "        with open(r'/Users/rajsharavan/Desktop/Python/Test/wordss.csv','w') as out:\n",
    "            csv_out=csv.writer(out)\n",
    "            csv_out.writerow('')\n",
    "            for row in items:\n",
    "                csv_out.writerow(row)\n",
    "\n",
    "    print_top1()\n",
    "\n",
    "    filtered_sentence_lowercase = [x.lower() for x in filtered_sentence]\n",
    "\n",
    "\n",
    "\n",
    "    contents1 = []\n",
    "    with open(r'/Users/rajsharavan/Desktop/Python/Test/WordList.csv','r') as csvf: # Open file in read mode\n",
    "        urls = csv.reader(csvf)\n",
    "        for url in urls:\n",
    "            contents1.append(url[0])\n",
    "        \n",
    "    contents2 = []\n",
    "    with open(r'/Users/rajsharavan/Desktop/Python/Test/tfidf_WordList.csv','r') as csvf1: # Open file in read mode\n",
    "        urls1 = csv.reader(csvf1)\n",
    "        for url1 in urls1:\n",
    "            contents2.append(url1[0])\n",
    "        \n",
    "    contents3 = []\n",
    "    with open(r'/Users/rajsharavan/Desktop/Python/Test/Words_TR.csv','r') as csvf2: # Open file in read mode\n",
    "        urls2 = csv.reader(csvf2)\n",
    "        for url2 in urls2:\n",
    "            contents3.append(url2[0])\n",
    "\n",
    "    list_of_contents = [contents1,contents2,contents3]\n",
    "\n",
    "    \n",
    "    for i in range(1, 101):\n",
    "        add.write(0,i+4,i)\n",
    "    list_no=1\n",
    "    for words in list_of_contents:\n",
    "        for num in words:\n",
    "            count = 0\n",
    "            for num1 in filtered_sentence_lowercase:\n",
    "                if num == num1:\n",
    "                    count = count+1\n",
    "            add.write(row,1, 'State Street')\n",
    "            add.write(row,2, '1')\n",
    "            add.write(row,3,joburl)\n",
    "            add.write(row,4, list_no)\n",
    "            add.write(row,col,count)\n",
    "            \n",
    "            col = col+1\n",
    "            if col == 105:\n",
    "                col = 5\n",
    "                row = row +1    \n",
    "        list_no = list_no+1\n",
    "    del all_contents[:]            \n",
    "    del filtered_sentence[:]\n",
    "    del filtered_sentence_lowercase[:]\n",
    "    \n",
    "wb.save('/Users/rajsharavan/Desktop/Python/Test/word_example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
